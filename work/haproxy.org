#+TITLE: HAproxy
#+AUTHOR: LavenLiu
#+DATE: 2010-08-20
#+EMAIL: ldczz2008@163.com 

#+STARTUP: OVERVIEW
#+TAGS: OFFICE(o) HOME(h) PROJECT(p) CHANGE(c) REPORT(r) MYSELF(m) 
#+TAGS: PROBLEM(P) INTERRUPTTED(i) RESEARCH(R)
#+SEQ_TODO: TODO(t)  STARTED(s) WAITING(W) | DONE(d) CANCELLED(C) DEFERRED(f)
#+COLUMNS: %40ITEM(Details) %TAGS(Context) %7TODO(To Do) %5Effort(Time){:} %6CLOCKSUM{Total}

#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper,11pt]
#+LaTeX_HEADER: \usepackage[top=2.1cm,bottom=2.1cm,left=2.1cm,right=2.1cm]{geometry}
#+LaTeX_HEADER: \setmainfont[Mapping=tex-text]{Times New Roman}
#+LaTeX_HEADER: \setsansfont[Mapping=tex-text]{Tahoma}
#+LaTeX_HEADER: \setmonofont{Courier New}
#+LaTeX_HEADER: \setCJKmainfont[BoldFont={Adobe Heiti Std},ItalicFont={Adobe Kaiti Std}]{Adobe Song Std}
#+LaTeX_HEADER: \setCJKsansfont{Adobe Heiti Std}
#+LaTeX_HEADER: \setCJKmonofont{Adobe Fangsong Std}
#+LaTeX_HEADER: \punctstyle{hangmobanjiao}
#+LaTeX_HEADER: \usepackage{color,graphicx}
#+LaTeX_HEADER: \usepackage[table]{xcolor}
#+LaTeX_HEADER: \usepackage{colortbl}
#+LaTeX_HEADER: \usepackage{listings}
#+LaTeX_HEADER: \usepackage[bf,small,indentafter,pagestyles]{titlesec}

#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="css/style2.css" />

#+OPTIONS: ^:nil
#+OPTIONS: tex:t

* HAproxy简介
* 集群中的文件存储
  1. 文件共享(NFS)
  2. 文件复制
  3. 文件分发
  4. 分布式文件系统
* 集群中的Session处理
  1. Session保持
  2. Session复制
  3. Session共享
* HAproxy自动化部署
* HAproxy配置
* 七层负载均衡配置
* HAproxy在线管理
* HAproxy监控
* HAproxy介绍
  HAproxy是一个开源的高性能的反向代理或者说是负载均衡服务软件之一，它
  支持双机热备、虚拟主机、基于TCP和HTTP应用代理等功能。其配置简单，而
  且拥有很好的对服务器节点的健康检查功能。当其代理的后端服务器出现故
  障时，HAproxy会自动将该故障服务器剔除，当服务器的故障恢复后，
  HAproxy还会自动将该RS加入到集群中。

  HAproxy特别适用于那些访问量很大，但又需要回话保持或七层应用的业务。
  HAproxy运行在普通的服务器硬件上，仅仅进行简单的优化就可以支持数以万
  计的并发连接。并且它的运行模式使得它可以很简单安全的整合进各种网站
  的架构中，同时web服务器不被暴露到公网上。

  从1.3版本起，HAproxy软件引入了frontend、backend功能。frontend（acl
  规则匹配）可以让运维管理人员根据任意HTTP请求头内容做规则匹配，然后
  把请求定向到相关的backend（后端服务器池）。通过frontend和backend，
  我们可以很容易实现了7层的代理功能，是一款不可多得的优秀代理服务软件。

  HAproxy支持两种主要的代理模式：4层TCP代理（例如：可用于邮件服务、内
  部协议通信服务器、MySQL业务等）和7层代理（如HTTP代理）。在4层TCP模
  式下，HAproxy仅在客户端和服务器之间双向转发流量。在7层代理模式下，
  HAproxy会分析应用层协议，并且能通过允许、拒绝、交换、增加、修改或者
  删除请求（request）或响应（response）里指定内容来控制协议。
* HAproxy解决方案拓扑图
** HAproxy四层负载均衡应用架构拓扑
   HAproxy软件的四层TCP代理应用非常优秀，配置非常简单方便，比LVS和
   Nginx要方便很多，因为不需要在RS端执行脚本即可实现代理。和商业版的
   NS（NetScaler）、F5等硬件的使用方法和在架构中的位置几乎一样。
   
   一张拓扑图:Haproxy_L4.jpeg

   说明，由于HAproxy采用的是NAT模式，数据包来去都会经过HAproxy，因此，
   在流量特别大的情况下，其性能不如LVS。

   在一般的中小型公司，建议使用haproxy做负载均衡，而不使用LVS或Nginx。
   Haproxy配置简单，维护方便。
** HAproxy七层负载均衡应用架构拓扑
   HAproxy的最大优点在于其7层的根据URL请求头应用过滤的功能，在门户网
   站的高并发生产架构中，HAproxy一般用在LVS软件的下一层，或者像官方推
   荐的可以挂在硬件负载均衡NS或F5下使用，其表现非常好。2009年起，
   taobao网的CDN业务就大面积使用HAproxy作为7层cache应用代理。

   一张拓扑图：haproxy_L7.jpeg
** 实施部署前L4主机规划列表
    | 名称   | 接口 |             IP | 说明                         |
    |--------+------+----------------+------------------------------|
    | Master | eth0 | 192.168.19.135 | 外网管理IP，用于WAN数据转发  |
    |        | eth1 | 192.168.20.135 | 内网管理IP，用于LAB数据转发  |
    |        | eth2 | 192.168.21.135 | 用于提供服务器间心跳（直连） |
    |--------+------+----------------+------------------------------|
    | VIP    |      | 192.168.19.100 |                              |
    |--------+------+----------------+------------------------------|
    | Backup | eth0 | 192.168.19.136 |                              |
    |        | eth1 | 192.168.20.136 |                              |
    |        | eth2 | 192.168.21.136 |                              |


    #+BEGIN_SRC sh
make TARGET=linux26 ARCH=x86_64
make PREFIX=/application/haproxy-1.5.15 install
make install
ln -s /application/haproxy-1.5.15 /application/haproxy
	#+END_SRC
** 创建HAproxy相关目录
    #+BEGIN_SRC sh
mkdir -p bin conf logs var/run var/chroot
useradd haproxy -s /sbin/nologin -M
cat /application/haproxy/bin/haproxy
cd conf
cat haproxy.conf
global
    chroot /application/haproxy-1.5.15/var/chroot
    daemon
    group haproxy
    user haproxy
    log 127.0.0.1:514 local0 info # 如果访问量大，关闭此配置；不然磁盘压力比较大；可以开启错误日志，而非访问日志；
    pidfile /application/haproxy-1.5.15/var/run/haproxy.pid

    maxconn 20480
    spread-checks 3
#   tune.maxaccept 100
#   tune.maxpollevents 180
    nbproc 8

defaults
    log global
    mode http
#   option httplog
#   option dontlognull
    retries 3
    option redispatch
    contimeout 5000
    clitimeout 50000
    srvtimeout 50000

listen www 192.168.20.100:80
    mode http
    no option splice-response
    stats enable
    stats uri /admin?stats
    stats auth myproxy:lavenliu
    balance roundrobin
    option httpclose
    option forwardfor # 让后端RS记录客户端IP地址，而非HaproxyIP地址
    option httpchk HEAD /checkstatus.html HTTP/1.0 # URL健康检查功能

    server www01 192.168.20.137:8080 check
    server www02 192.168.20.138:8080 check
    # server www03 192.168.20.139:8080
    #+END_SRC
* Install
  #+BEGIN_SRC sh
make TARGET=linux26 ARCH=x86_64
make PREFIX=/application/haproxy-1.5.15 install
make install
ln -s /application/haproxy-1.5.15 /application/haproxy
  #+END_SRC

  创建HAproxy相关目录，
  #+BEGIN_SRC sh
mkdir -p bin conf logs var/run var/chroot
useradd haproxy -s /sbin/nologin -M
cat /application/haproxy/bin/haproxy
cd conf
cat haproxy.conf
  #+END_SRC
** yum方式安装Haproxy
   #+BEGIN_SRC sh
yum install -y haproxy
   #+END_SRC
** 设置监控页面
   #+BEGIN_SRC sh
# 在listen或backed或defaults配置段下添加
stats   uri /admin?stats
stats   auth myproxy:lavenliu
   #+END_SRC
* start script
  #+BEGIN_SRC sh
# cat /application/haproxy/bin/haproxy
#!/bin/bash

BASE="/application/haproxy-1.5.15"

PROG=$BASE/sbin/haproxy
PIDFILE=$BASE/var/run/haproxy.pid
CONFFILE=$BASE/conf/haproxy.conf

case "$1" in
start)
	#$PROG -f $CONFFILE >/dev/null 2>&1
	$PROG -f $CONFFILE
	;;
status)
	if [ ! -f $PIDFILE ]; then
		echo "pid not found"
		exit 1
	fi
	for pid in $(cat $PIDFILE); do
		kill -0 $pid
		RETVAL="$?"
		if [ ! "$RETVAL" = "0" ]; then
			echo "process $pid died"
			exit 1
		fi
	done
	echo "process is running"
	;;
restart)
	$PROG -f $CONFFILE -sf $(cat $PIDFILE) >/dev/null 2>&1
	;;
stop)
	kill $(cat $PIDFILE)
	;;
,*)
	echo "USAGE: $0 start|restart|status|stop"
	exit 1
	;;
esac
  #+END_SRC

  启动完毕，可以查看Haproxy的状态界面信息，
  #+BEGIN_SRC sh
http://<vip>/admin?stats
myproxy:lavenliu
  #+END_SRC
* Haproxy日志配置
  编辑/etc/syslog.conf增加如下配置，
  #+BEGIN_SRC sh
# begin haproxy
local0.* /application/haproxy-1.5.15/logs/haproxy.log
# end haproxy
  #+END_SRC

  编辑/etc/sysconfig/syslog，增加如下配置，
  #+BEGIN_SRC sh
# -m 0 disables 'MARK' messages
# -r enables logging from remote machines
# -x disables DNS lookups on messages recieved with -r
SYSLOGD_OPTIONS="-m 0 -r -x"
# 重启rsyslog服务
/etc/init.d/rsyslog restart
netstat -antup |grep 514
  #+END_SRC
* Haproxy监控检查功能
** 基于端口的健康检查
   #+BEGIN_SRC sh
# 一般的书写形式
server  app1 192.168.0.114:80 check
server  app2 192.168.0.116:80 check
# 比较详细的书写形式
server  app1 192.168.0.114:80 cookie app1 check port 8080 inter 5000 fall 5
server  app2 192.168.0.116:80 cookie app2 check port 8080 inter 5000 fall 5
## 提示
check port 80 # 表示对8080进行健康检查
inter 5000 fall 5 # 表示每5秒检查一次，一共检查5次
# 如果不加inter 5000 fall 5，则默认每2秒检查一次，一共检查3次。
# 如果有问题就会剔除有问题的机器
# 如果RS节点比较多，检查时间可以短一点；
# 如果RS节点比较少，检查时间可以长一点；
## cookie
# 每一个请求插入一个cookie，实现一个会话保持的功能
   #+END_SRC

   相关参数的默认值，
   #+BEGIN_SRC sh
- inter : 2000 意思是不加该参数，正常情况默认每两秒检查一次
- rise  : 2    意思是不加该参数，在RS宕机后且恢复前，检查2次OK，则认为其复活，并加入集群组中
- fall  : 3    意思是不加该参数，检查3次后，认为RS宕机，剔除集群组
- port  : default server port 不加该参数，默认就是端口检查
- addr  : specific address for the test (default = address server)
   #+END_SRC

   对用户体验非常严格，就不要使用基于TCP端口方式的健康检查。
** 基于URL的健康检查
   #+BEGIN_SRC sh
option httpchk HEAD /checkstatus.html HTTP/1.0
server app58 192.168.0.58:80 maxconn 2048 weight 10 check inter 3000 fall 2 rise 2
# 要确保每个RS节点有checkstatus.html文件
# 其实Haproxy相当于使用如下的方式去检查
curl http://<vip>/checkstatus.html
## maxconn 2048 最大连接数
## weight 10 权重
   #+END_SRC
** 基于具体业务域名的URL健康检查
   基于域名的URL健康检查：实际上，可以理解为Haproxy用下面的方式在访问RS节点确认是否正常来检查。
   #+BEGIN_SRC sh
curl http://www.lavenliu.com/index.html或wget http://www.lavenliu.com/index.html
   #+END_SRC
   这种检测方式，适用于更精细的基于具体业务的检测需求。实际上是带着
   head host头部信息向下健康检查的。

   #+BEGIN_SRC sh
option httpchk HEAD /index.html HTTP/1.1\r\nHost:\ www.lavenliu.com
   #+END_SRC
** 生产环境如何正确选择健康检查
   本小节内容适用于所有负载均衡软件的健康检查

   1. 常规业务可以使用基于TCP的方式做健康检查，我们在keepalived健康检
      查时就是这样做的，虽然keepalived也支持URL健康检查；
   2. 由于基于URL的方式做健康检查相对来说比较容易配置，所以，推荐使用
      基于URL的健康检查。可以用http://192.168.20.135/checkstatus.html的方式，也可以使用基于域名的
	  http://www.lavenliu.com/checkstatus.html的方式，后者更高级一些；
   3. 实际生产环境中，最重要最关键的是，我们设置的checkstatus.html能否
      真正的代表RS上的业务状态，即访问checkstatus.html正常，整个业务是
      否能正常，这个需要运维及开发人员去分析的；
   4. 对于用户体验比较高的业务，可以请开发人员设置更加深入的健康检查文
      件，例如lavenliu.php，这个健康检查可以深入到数据库，存储及各个接
      口，如果其中之一出现异常我们就剔除，到底如何做还是需要去思考的，
      实际工作中不是做的越高级越好，根据业务需求达到需求就是可以的；
   5. 对于用户体验比较高的业务，除了健康文件更深入外，健康检查的频率、次数都要相应调整；
* Haproxy生产相关功能应用
** Haproxy高可用参数backup功能测试
   #+BEGIN_SRC sh
backend app
    balance     roundrobin

    stats   uri /admin?stats
    stats   auth myproxy:lavenliu

    option httpchk HEAD /checkstatus.html HTTP/1.0
    server  app1 192.168.0.114:80 check
    server  app2 192.168.0.116:80 check backup
   #+END_SRC
   此时，app2这台机器已不能对外提供服务了。只有app1这台机器进行对外提
   供服务。如果app1出现问题，那么app2将会接管app1进行对外提供服务。

   默认情况下，backup只有在所有非backup机器都停止服务时，才会接管服务。
   当RS节点很多时，可以设置当n台非backup的机器宕机时，就启用backup的机器。
** Haproxy下的RS无法记录客户端真实IP问题
   分两个步骤，
   1. 在Haproxy的配置文件里添加如下的配置，加在listen或backend配置段里，
      #+BEGIN_SRC sh
option forwardfor
	  #+END_SRC
   2. 在RS上对日志格式进行修改（httpd或Nginx）
	  + httpd的日志格式
		#+BEGIN_SRC sh
LogFormat "\"%{X-Forwarded-For}i\" %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"" combined
#LogFormat "\"%{X-Forwarded-For}i\"%V %A %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"" combined
		#+END_SRC
	  + Nginx的日志格式


   生产环境负载均衡后面的RS服务器不记录监控检查文件日志（checkstatus.html）:
   #+BEGIN_SRC sh
SetEnvIf Request_RUI "^/checkstatus\.html$" dontlog
LogLevel warn
ErrorLog /var/log/httpd/vhost_error.log
CustomLog /var/log/httpd/vhost_access.log combined env=!dontlog
   #+END_SRC
** 主备Haproxy配置文件区别
   主备Haproxy配置文件完全一样，没有任何不同。
** 解决服务器不存在VIP导致启动Haproxy报错问题
   如果出现下面错误，
   #+BEGIN_SRC sh
/application/haproxy-1.5.15/bin/haproxy restart
Starting proxy group: cannot bind socket
   #+END_SRC

   解决办法，在/etc/sysctl.conf中加入如下配置，
   #+BEGIN_SRC sh
net.ipv4.ip_nonlocal_bind = 1
## 注
1. net.ipv4.ip_forward = 1 # 负载均衡器都需要打开系统转发功能
2. net.ipv4.ip_nonlocal_bind = 1 # 此项使Haproxy忽略其配置中的VIP是否存在。
# 因为要实施双主即主备同时跑服务，所以每一端的VIP都在配置文件里配置了，但系统的
# 网卡实际上可能不存在VIP，因此报错。
   #+END_SRC

   也可以使用如下命令快速添加，
   #+BEGIN_SRC sh
echo 'net.ipv4.ip_nonlocal_bind = 1' >> /etc/sysctl.conf
   #+END_SRC

   也有可能是端口冲突。
** 生产环境防火墙iptables配置建议
   生产环境高访问量站点，iptables防火墙可能对LB性能有影响，最好前端加硬件防火墙。
** heartbeat或keepalived与Haproxy关联问题
   在生产环境中，Haproxy可能会配合heartbeat或keepalived使用，当Haproxy无法提供服务时，
   要不要把业务转移到备机？

   可以做个实验，在主节点上使用kill命令强制杀掉Haproxy进程，这时VIP依
   然在主节点上，客户端通过这个VIP访问站点时，肯定是获取不到资源的。因
   此，当Haproxy无法提供服务时，要把业务转移到备机上。

   一般情况下这个问题不会发生，如果严格去做的话，可以单独写一个守护进
   程脚本，在主节点使用脚本检测Haproxy的进程是否存在，如果不存在就强制
   停止heartbeat或keepalived进程，使得VIP漂移到备节点。
** Haproxy日志配置优化
   在高并发环境下，Haproxy日志级别最好使用warning及以上级别。日志信息
   太详细会影响Haproxy的性能。
** Haproxy多业务多VIP的配置
   defaults，
   #+BEGIN_SRC sh
option httpclose
stats enable
stats uri /admin?stats
stats auth myproxy:lavenliu
cookie SERVERID insert
   #+END_SRC
   多添加几个listen或backend即可，
   #+BEGIN_SRC sh
# 七层代理例子
backend www
    bind 192.168.20.100:80
    mode http
    balance roundrobin
    option forwardfor
    option httpchk HEAD /checkstatus.html HTTP/1.0
    server www01 192.168.20.134:80 check
    server www02 192.168.20.135:80 check
    server www03 192.168.20.136:80 check

# 四层代理例子
backend ssh
    bind 192.168.20.200:8000
    mode tcp
    balance roundrobin
    server ssh01 192.168.20.135:22 check
   #+END_SRC
   
   可以做如下测试，
   #+BEGIN_SRC sh
ssh -p 8000 192.168.20.200
   #+END_SRC
** Haproxy多实例的配置
   多个配置文件里的Haproxy的pid文件不能一样，listen或backend后面的字段
   不能一样，bind不能一样。
   
   如何启动呢？可以使用haproxy命令，然后指定不同的配置文件即可。

   类似于MySQL的多实例。
** Haproxy维护总结
   负载均衡和高可用服务器的位置一般来说都非常重要，因此，操作时一定要
   谨慎小心，一定要记得事先写好操作步骤及回滚步骤，然后，再去实施操作。如果直接动手操作，
   那样会极容易导致网站宕机影响用户体验，特别是涉及到数据库和存储高可用就要更加小心了。

   流量高峰期不允许轻易操作负载均衡服务器上的相关配置等。

   查看负载均衡器的日志信息及系统信息。
* Haproxy的L7生产应用实战
** RS web server测试环境准备
   在/var目录下分别建立php、nginx、resin等3个站点目录，并增加index文件
   及内容，假设php、nginx、resin分别代表解析不同的业务服务，
   #+BEGIN_SRC sh
## 在minion01上进行操作
# php表示动态PHP程序服务
# nginx表示静态图片、js、html等服务
# resin表示动态jsp/java服务
for name in php nginx resin ; do mkdir -p /var/$name ; echo $name > /var/$name/index.html ; done
yum install -y httpd
# 编辑/etc/httpd/conf.d/httpd-vhosts.conf，
<Directory "/var">
    Options FollowSymLinks
    AllowOverride none
    Order allow,deny
    Allow from all
</Directory>

NameVirtualHost *:80
NameVirtualHost *:8000
NameVirtualHost *:8001
NameVirtualHost *:8002

<VirtualHost *:8000>
    ServerAdmin  1846122963@qq.com
    ServerName   nginx.lavenliu.com
    ServerAlias  lavenliu.com
    DocumentRoot "/var/nginx"
</VirtualHost>

<VirtualHost *:8001>
    ServerAdmin  1846122963@qq.com
    ServerName   php.lavenliu.com
    DocumentRoot "/var/php"
</VirtualHost>

<VirtualHost *:8002>
    ServerAdmin  1846122963@qq.com
    ServerName   resin.lavenliu.com
    DocumentRoot "/var/resin"
</VirtualHost>

## 修改主配置文件httpd.conf
Listen 80
Listen 8000
Listen 8001
Listen 8002
#
# 检查配置语法
/etc/init.d/httpd configtest
# 启动并测试
/etc/init.d/httpd start
lsof -i:80
   #+END_SRC

   添加域名解析，在C:\Windows\system32\dirvers\etc\hosts，
   #+BEGIN_SRC sh
192.168.20.135 nginx.lavenliu.com
192.168.20.135 php.lavenliu.com
192.168.20.135 resin.lavenliu.com
192.168.20.135 lavenliu.com
   #+END_SRC

   使用浏览器进行测试。
** Haproxy负载均衡器配置
   #+BEGIN_SRC sh
## 在192.168.20.134上进行操作
frontend webserver
    bind 192.168.20.100:80
## 1. 实现301跳转
# 需求，lavenliu.com -> nginx.lavenliu.com (301)
# short_dom为自定义名称，hdr函数包含Host -i(不区分大小写)匹配lavenliu.com
    acl short_dom hdr(Host) -i lavenliu.com

    # prefix 前缀跳转 保证访问http://lavenliu.com/a.html能够跳转到http://nginx.lavenliu.com/a.html
    redirect prefix http://nginx.lavenliu.com code 301 if short_dom

    acl lavenliu_static path_beg /nginx/
    acl lavenliu_php path_beg /php/
    acl lavenliu_java path_beg /resin/

    # acl lavenliu_pic path_end .gif .png .jpg .css .js

    use_backend nginxpool if lavenliu_static or lavenliu_pic
    use_backend phppool if lavenliu_php
    use_backend javapool if lavenliu_java

    default_backend nginxpool

# nginx static contents
backend nginxpool
    balance roundrobin
    server laven8000 192.168.20.135:8000

# php contents
backend phppool
    balance roundrobin
    server laven8001 192.168.20.135:8001

# java contents
backend javapool
    balance roundrobin
    server laven8002 192.168.20.135:8002
   #+END_SRC
   
   如果日志文件有问题，则检查selinux是否开启。
*** 实现基于URL地址目录做7层跳转
	#+BEGIN_SRC sh
    # 定义
    acl lavenliu_static path_beg /nginx/
    acl lavenliu_php path_beg /php/
    acl lavenliu_java path_beg /resin/

    # acl lavenliu_pic path_end .gif .png .jpg .css .js

    # 判断
    use_backend nginxpool if lavenliu_static or lavenliu_pic
    use_backend phppool if lavenliu_php
    use_backend javapool if lavenliu_java
	#+END_SRC
	
	以上内容实现了：
	#+BEGIN_EXAMPLE
访问http://nginx.lavenliu.com/nginx/ -> nginxpool后端处理
访问http://php.lavenliu.com/php/ -> phppool后端处理
访问http://resin.lavenliu.com/resin/ -> javapool后端处理
	#+END_EXAMPLE
*** 实现基于文件扩展名做7层跳转
	#+BEGIN_SRC sh
    acl lavenliu_pic path_end .gif .png .jpg .css .js

    use_backend nginxpool if lavenliu_static or lavenliu_pic
	#+END_SRC
*** 实现基于user_agent做7层跳转
	#+BEGIN_SRC sh
acl iphone_users hdr_sub(user-agent) -i iphone
redirect prefix http://3g-iphone.lavenliu.com if iphone_users

acl android_users hdr_sub(user-agent) -i android
redirect prefix http://3g-android.lavenliu.com if android_users
	#+END_SRC
